{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Connected Function Calling with Ollama\n",
    "\n",
    "### Requirements\n",
    "\n",
    "#### 1. Ollama\n",
    "\n",
    "Ollama installation instructions per OS (macOS, Linux, Windows) can be found on [their website](https://ollama.com/download). For Linux simply (run cell below if not installed): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Python Ollama Library\n",
    "\n",
    "For that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Pull the model from Ollama\n",
    "\n",
    "Download the q8 quantized NousHermes-2-Pro-Mistral-7B from Ollama (uploaded by adrienbrault):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull adrienbrault/nous-hermes2pro:Q8_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "#### 1. Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_weather_forecast(location: str) -> dict[str, str]:\n",
    "    \"\"\"Retrieves the weather forecast for a given location\"\"\"\n",
    "    # Mock values for test\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"forecast\": \"sunny\",\n",
    "        \"temperature\": \"25Â°C\",\n",
    "    }\n",
    "\n",
    "def get_random_city() -> str:\n",
    "    \"\"\"Retrieves a random city from a list of cities\"\"\"\n",
    "    cities = [\"Groningen\", \"Enschede\", \"Amsterdam\", \"Istanbul\", \"Baghdad\", \"Rio de Janeiro\", \"Tokyo\", \"Kampala\"]\n",
    "    return random.choice(cities)\n",
    "\n",
    "def get_random_number() -> int:\n",
    "    \"\"\"Retrieves a random number\"\"\"\n",
    "    # Mock value for test\n",
    "    return 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define Function Caller\n",
    "\n",
    "For this example in Jupyter format, I'm simply putting the functions in a list. In a python project, you can use the implementation here as an inspiration: https://github.com/AtakanTekparmak/ollama_langhcain_fn_calling/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "class FunctionCaller:\n",
    "    \"\"\"\n",
    "    A class to call functions from tools.py.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize the functions dictionary\n",
    "        self.functions = {\n",
    "            \"get_weather_forecast\": get_weather_forecast,\n",
    "            \"get_random_city\": get_random_city,\n",
    "            \"get_random_number\": get_random_number,\n",
    "        }\n",
    "        self.outputs = {}\n",
    "\n",
    "    def create_functions_metadata(self) -> list[dict]:\n",
    "        \"\"\"Creates the functions metadata for the prompt. \"\"\"\n",
    "        def format_type(p_type: str) -> str:\n",
    "            \"\"\"Format the type of the parameter.\"\"\"\n",
    "            # If p_type begins with \"<class\", then it is a class type\n",
    "            if p_type.startswith(\"<class\"):\n",
    "                # Get the class name from the type\n",
    "                p_type = p_type.split(\"'\")[1]\n",
    "            \n",
    "            return p_type\n",
    "            \n",
    "        functions_metadata = []\n",
    "        i = 0\n",
    "        for name, function in self.functions.items():\n",
    "            i += 1\n",
    "            descriptions = function.__doc__.split(\"\\n\")\n",
    "            print(descriptions)\n",
    "            functions_metadata.append({\n",
    "                \"name\": name,\n",
    "                \"description\": descriptions[0],\n",
    "                \"parameters\": {\n",
    "                    \"properties\": [ # Get the parameters for the function\n",
    "                        {   \n",
    "                            \"name\": param_name,\n",
    "                            \"type\": format_type(str(param_type)),\n",
    "                        }\n",
    "                        # Remove the return type from the parameters\n",
    "                        for param_name, param_type in function.__annotations__.items() if param_name != \"return\"\n",
    "                    ],\n",
    "                    \n",
    "                    \"required\": [param_name for param_name in function.__annotations__ if param_name != \"return\"],\n",
    "                } if function.__annotations__ else {},\n",
    "                \"returns\": [\n",
    "                    {\n",
    "                        \"name\": name + \"_output\",\n",
    "                        \"type\": {param_name: format_type(str(param_type)) for param_name, param_type in function.__annotations__.items() if param_name == \"return\"}[\"return\"]\n",
    "                    }\n",
    "                ]\n",
    "            })\n",
    "\n",
    "        return functions_metadata\n",
    "\n",
    "    def call_function(self, function):\n",
    "        \"\"\"\n",
    "        Call the function from the given input.\n",
    "\n",
    "        Args:\n",
    "            function (dict): A dictionary containing the function details.\n",
    "        \"\"\"\n",
    "    \n",
    "        def check_if_input_is_output(input: dict) -> dict:\n",
    "            \"\"\"Check if the input is an output from a previous function.\"\"\"\n",
    "            for key, value in input.items():\n",
    "                if value in self.outputs:\n",
    "                    input[key] = self.outputs[value]\n",
    "            return input\n",
    "\n",
    "        # Get the function name from the function dictionary\n",
    "        function_name = function[\"name\"]\n",
    "        \n",
    "        # Get the function params from the function dictionary\n",
    "        function_input = function[\"params\"] if \"params\" in function else None\n",
    "        function_input = check_if_input_is_output(function_input) if function_input else None\n",
    "    \n",
    "        # Call the function from tools.py with the given input\n",
    "        # pass all the arguments to the function from the function_input\n",
    "        output = self.functions[function_name](**function_input) if function_input else self.functions[function_name]()\n",
    "        self.outputs[function[\"output\"]] = output\n",
    "        return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Setup The Function Caller and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Retrieves the weather forecast for a given location']\n",
      "['Retrieves a random city from a list of cities']\n",
      "['Retrieves a random number']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the FunctionCaller \n",
    "function_caller = FunctionCaller()\n",
    "\n",
    "# Create the functions metadata\n",
    "functions_metadata = function_caller.create_functions_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create the system prompt\n",
    "prompt_beginning = \"\"\"\n",
    "You are an AI assistant that can help the user with a variety of tasks. You have access to the following functions:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_end = \"\"\"\n",
    "\n",
    "When the user asks you a question, if you need to use functions, provide ONLY the function calls, and NOTHING ELSE, in the format:\n",
    "<function_calls>    \n",
    "[\n",
    "    { \"name\": \"function_name_1\", \"params\": { \"param_1\": \"value_1\", \"param_2\": \"value_2\" }, \"output\": \"The output variable name, to be possibly used as input for another function},\n",
    "    { \"name\": \"function_name_2\", \"params\": { \"param_3\": \"value_3\", \"param_4\": \"output_1\"}, \"output\": \"The output variable name, to be possibly used as input for another function\"},\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "system_prompt = prompt_beginning + f\"<tools> {json.dumps(functions_metadata, indent=4)} </tools>\" + system_prompt_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Final Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'adrienbrault/nous-hermes2pro:Q4_0', 'created_at': '2024-04-25T16:34:12.473214Z', 'message': {'role': 'assistant', 'content': '<function_calls>\\n[\\n    {\\n        \"name\": \"get_random_city\",\\n        \"output\": \"random_city\"\\n    },\\n    {\\n        \"name\": \"get_weather_forecast\",\\n        \"params\": {\\n            \"location\": \"random_city\"\\n        },\\n        \"output\": \"weather_forecast\"\\n    }\\n]'}, 'done': True, 'total_duration': 6260727917, 'load_duration': 19787625, 'prompt_eval_duration': 1078901000, 'eval_count': 89, 'eval_duration': 5150607000}\n",
      "Function calls:\n",
      "[{'name': 'get_random_city', 'output': 'random_city'}, {'name': 'get_weather_forecast', 'params': {'location': 'random_city'}, 'output': 'weather_forecast'}]\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Compose the prompt \n",
    "user_query = \"Can you get me the weather forecast for a random city?\"\n",
    "\n",
    "# Get the response from the model\n",
    "model_name = 'adrienbrault/nous-hermes2pro:Q8_0'\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_prompt,\n",
    "    },\n",
    "    {'role': 'user', 'content': user_query}\n",
    "]\n",
    "response = ollama.chat(model=model_name, messages=messages)\n",
    "print(response)\n",
    "# Get the function calls from the response\n",
    "function_calls = response[\"message\"][\"content\"]\n",
    "# If it ends with a <function_calls>, get everything before it\n",
    "if function_calls.startswith(\"<function_calls>\"):\n",
    "    function_calls = function_calls.split(\"<function_calls>\")[1]\n",
    "\n",
    "# Read function calls as json\n",
    "try:\n",
    "    function_calls_json: list[dict[str, str]] = json.loads(function_calls)\n",
    "except json.JSONDecodeError:\n",
    "    function_calls_json = []\n",
    "    print (\"Model response not in desired JSON format\")\n",
    "finally:\n",
    "    print(\"Function calls:\")\n",
    "    print(function_calls_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response: {'location': 'Kampala', 'forecast': 'sunny', 'temperature': '25Â°C'}\n"
     ]
    }
   ],
   "source": [
    "# Call the functions\n",
    "output = \"\"\n",
    "for function in function_calls_json:\n",
    "    output = f\"Agent Response: {function_caller.call_function(function)}\"\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
