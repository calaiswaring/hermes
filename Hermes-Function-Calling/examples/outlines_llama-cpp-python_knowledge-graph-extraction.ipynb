{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d66530-b4e2-4b47-9413-92240069c5e1",
   "metadata": {},
   "source": [
    "# Knowledge Graph Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652e68d-4278-4e8f-9132-6ba90905d073",
   "metadata": {},
   "source": [
    "In this guide, we use [outlines](https://outlines-dev.github.io/outlines/) extract a knowledge graph from unstructured text with the quantized `Hermes-2-Pro-Llama-3-8B`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f30dda-18f6-415e-ac23-e87aeb636f83",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "### Install llama-cpp-python and outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467c6655-4dd6-4f4e-ad9b-42fc1de0f52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:04:58.229304Z",
     "iopub.status.busy": "2024-08-08T18:04:58.228803Z",
     "iopub.status.idle": "2024-08-08T18:04:58.234608Z",
     "shell.execute_reply": "2024-08-08T18:04:58.233551Z",
     "shell.execute_reply.started": "2024-08-08T18:04:58.229253Z"
    }
   },
   "outputs": [],
   "source": [
    "# RUN IT ONLY ONCE TO INSTALL THE REQUIREMENTS\n",
    "# %pip install llama-cpp-python outlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da62069-96d7-43e5-8968-64b48bc1384b",
   "metadata": {},
   "source": [
    "For detailed installation instructions, see [llama-cpp-python installation](https://llama-cpp-python.readthedocs.io/en/stable/) and [outlines installation](https://outlines-dev.github.io/outlines/installation/)\n",
    "\n",
    "### Pull the model from HuggingFace\n",
    "\n",
    "Download a GGUF model from HuggingFace [here](https://huggingface.co/NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF/tree/main), for example, the Q4_K_M one (it requires 4.92 GB):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6e9b01-0ad9-4f40-ac99-2e9340c1d3b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:04:58.236585Z",
     "iopub.status.busy": "2024-08-08T18:04:58.235932Z",
     "iopub.status.idle": "2024-08-08T18:04:58.260585Z",
     "shell.execute_reply": "2024-08-08T18:04:58.259247Z",
     "shell.execute_reply.started": "2024-08-08T18:04:58.236542Z"
    }
   },
   "outputs": [],
   "source": [
    "# RUN IT ONLY ONCE TO DOWNLOAD THE GGUF MODEL, IN THIS CASE THE Q4_K_M\n",
    "# !wget https://hf.co/NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF/resolve/main/Hermes-2-Pro-Llama-3-8B-Q4_K_M.gguf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fa3ae-28bf-4636-9f23-92b3204df17d",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "### Knowledge Graph Extraction\n",
    "\n",
    "### Define Pydantic class\n",
    "\n",
    "We first need to define our Pydantic class for each node and each edge of the knowledge graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ec8443-533b-41a5-9cfd-7e3ef23c57fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:04:58.262654Z",
     "iopub.status.busy": "2024-08-08T18:04:58.262170Z",
     "iopub.status.idle": "2024-08-08T18:04:58.389248Z",
     "shell.execute_reply": "2024-08-08T18:04:58.388288Z",
     "shell.execute_reply.started": "2024-08-08T18:04:58.262605Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Node(BaseModel):\n",
    "    \"\"\"Node of the Knowledge Graph\"\"\"\n",
    "\n",
    "    id: int = Field(..., description=\"Unique identifier of the node\")\n",
    "    label: str = Field(..., description=\"Label of the node\")\n",
    "    property: str = Field(..., description=\"Property of the node\")\n",
    "\n",
    "\n",
    "class Edge(BaseModel):\n",
    "    \"\"\"Edge of the Knowledge Graph\"\"\"\n",
    "\n",
    "    source: int = Field(..., description=\"Unique source of the edge\")\n",
    "    target: int = Field(..., description=\"Unique target of the edge\")\n",
    "    label: str = Field(..., description=\"Label of the edge\")\n",
    "    property: str = Field(..., description=\"Property of the edge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2766c4-9c46-4fc8-a485-3b322da761a6",
   "metadata": {},
   "source": [
    "We then define the Pydantic class for the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2712e4-57d9-4466-abda-87cf7bd29f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:04:58.390871Z",
     "iopub.status.busy": "2024-08-08T18:04:58.390385Z",
     "iopub.status.idle": "2024-08-08T18:04:58.400975Z",
     "shell.execute_reply": "2024-08-08T18:04:58.399576Z",
     "shell.execute_reply.started": "2024-08-08T18:04:58.390835Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Generated Knowledge Graph\"\"\"\n",
    "\n",
    "    nodes: List[Node] = Field(..., description=\"List of nodes of the knowledge graph\")\n",
    "    edges: List[Edge] = Field(..., description=\"List of edges of the knowledge graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83358efd-2411-4383-962e-109b9d8afcc8",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f2fe73-56f7-4533-9357-394d5c6555dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:04:58.403495Z",
     "iopub.status.busy": "2024-08-08T18:04:58.402478Z",
     "iopub.status.idle": "2024-08-08T18:05:04.124226Z",
     "shell.execute_reply": "2024-08-08T18:05:04.123430Z",
     "shell.execute_reply.started": "2024-08-08T18:04:58.403442Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import llama_cpp\n",
    "from llama_cpp import Llama\n",
    "from outlines import generate, models\n",
    "\n",
    "llm = Llama(\n",
    "    \"/big_storage/llms/models/Hermes-2-Pro-Llama-3-8B-Q4_K_M.gguf\",\n",
    "    tokenizer=llama_cpp.llama_tokenizer.LlamaHFTokenizer.from_pretrained(\n",
    "        \"NousResearch/Hermes-2-Pro-Llama-3-8B\"\n",
    "    ),\n",
    "    n_gpu_layers=-1,\n",
    "    flash_attn=True,\n",
    "    n_ctx=8192,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model = models.LlamaCpp(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33f0a08-a699-4682-a50a-e5b21acb7645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:05:04.126037Z",
     "iopub.status.busy": "2024-08-08T18:05:04.125778Z",
     "iopub.status.idle": "2024-08-08T18:05:04.129996Z",
     "shell.execute_reply": "2024-08-08T18:05:04.128974Z",
     "shell.execute_reply.started": "2024-08-08T18:05:04.126017Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) # ignore runtime warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91149a2f-0d15-4d8f-8827-73a15a38464f",
   "metadata": {},
   "source": [
    "We build a regex from the `KnowledgeGraph` Pydantic class which the model will be forced to follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a125eb20-efb2-4274-a42d-a35f58d9db54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:05:04.132103Z",
     "iopub.status.busy": "2024-08-08T18:05:04.131434Z",
     "iopub.status.idle": "2024-08-08T18:05:04.169395Z",
     "shell.execute_reply": "2024-08-08T18:05:04.168357Z",
     "shell.execute_reply.started": "2024-08-08T18:05:04.132046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\{[ ]?\"nodes\"[ ]?:[ ]?\\\\[[ ]?((\\\\{[ ]?\"id\"[ ]?:[ ]?(-)?(0|[1-9][0-9]*)[ ]?,[ ]?\"label\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?,[ ]?\"property\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?\\\\})(,[ ]?(\\\\{[ ]?\"id\"[ ]?:[ ]?(-)?(0|[1-9][0-9]*)[ ]?,[ ]?\"label\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?,[ ]?\"property\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?\\\\})){0,})?[ ]?\\\\][ ]?,[ ]?\"edges\"[ ]?:[ ]?\\\\[[ ]?((\\\\{[ ]?\"source\"[ ]?:[ ]?(-)?(0|[1-9][0-9]*)[ ]?,[ ]?\"target\"[ ]?:[ ]?(-)?(0|[1-9][0-9]*)[ ]?,[ ]?\"label\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?,[ ]?\"property\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?\\\\})(,[ ]?(\\\\{[ ]?\"source\"[ ]?:[ ]?(-)?(0|[1-9][0-9]*)[ ]?,[ ]?\"target\"[ ]?:[ ]?(-)?(0|[1-9][0-9]*)[ ]?,[ ]?\"label\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?,[ ]?\"property\"[ ]?:[ ]?\"([^\"\\\\\\\\\\\\x00-\\\\x1F\\\\x7F-\\\\x9F]|\\\\\\\\[\"\\\\\\\\])*\"[ ]?\\\\})){0,})?[ ]?\\\\][ ]?\\\\}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from outlines.integrations.utils import convert_json_schema_to_str\n",
    "from outlines.fsm.json_schema import build_regex_from_schema\n",
    "\n",
    "json_schema = KnowledgeGraph.model_json_schema()\n",
    "schema_str = convert_json_schema_to_str(json_schema=json_schema)\n",
    "regex_str = build_regex_from_schema(schema_str)\n",
    "regex_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a853e5b6-1a40-43aa-a03d-4d5ece02b9c7",
   "metadata": {},
   "source": [
    "We then need to adapt our prompt to the [Hermes prompt format for JSON schema](https://github.com/NousResearch/Hermes-Function-Calling?tab=readme-ov-file#prompt-format-for-json-mode--structured-outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fddb1a4-fc3d-4a81-bfb6-ab07c94c16e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:05:04.171390Z",
     "iopub.status.busy": "2024-08-08T18:05:04.170807Z",
     "iopub.status.idle": "2024-08-08T18:05:04.177013Z",
     "shell.execute_reply": "2024-08-08T18:05:04.175983Z",
     "shell.execute_reply.started": "2024-08-08T18:05:04.171342Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_hermes_prompt(user_prompt):\n",
    "    return (\n",
    "        \"<|im_start|>system\\n\"\n",
    "        \"You are a world class AI model who answers questions in JSON with correct Pydantic schema. \"\n",
    "        \"Here's the json schema you must adhere to:\\n<schema>\\n\" + str(json_schema) + \"\\n</schema>\"\n",
    "        \"\\n<|im_start|>user\\n\" + user_prompt + \"<|im_end|>\"\n",
    "        \"\\n<|im_start|>assistant\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5de546b-8dab-4125-a478-ceee0eaa3225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:05:04.179280Z",
     "iopub.status.busy": "2024-08-08T18:05:04.178432Z",
     "iopub.status.idle": "2024-08-08T18:05:04.200243Z",
     "shell.execute_reply": "2024-08-08T18:05:04.198925Z",
     "shell.execute_reply.started": "2024-08-08T18:05:04.179233Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_hermes_prompt(user_prompt):\n",
    "    return (\n",
    "        \"<|im_start|>system\\n\"\n",
    "        \"You are a world class AI model who answers questions in JSON \"\n",
    "        f\"Here's the json schema you must adhere to:\\n<schema>\\n{json_schema}\\n</schema><|im_end|>\\n\"\n",
    "        \"<|im_start|>user\\n\"\n",
    "        + user_prompt\n",
    "        + \"<|im_end|>\"\n",
    "        + \"\\n<|im_start|>assistant\\n\"\n",
    "        \"<schema>\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133966dc-642a-4c64-983a-66f0ece78b2b",
   "metadata": {},
   "source": [
    "For a given `user_prompt` we obtain the hermes prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e64535be-9597-49c9-a8e9-6d0598c74ec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:05:04.202188Z",
     "iopub.status.busy": "2024-08-08T18:05:04.201721Z",
     "iopub.status.idle": "2024-08-08T18:05:04.218040Z",
     "shell.execute_reply": "2024-08-08T18:05:04.216790Z",
     "shell.execute_reply.started": "2024-08-08T18:05:04.202142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a world class AI model who answers questions in JSON Here's the json schema you must adhere to:\n",
      "<schema>\n",
      "{'$defs': {'Edge': {'description': 'Edge of the Knowledge Graph', 'properties': {'source': {'description': 'Unique source of the edge', 'title': 'Source', 'type': 'integer'}, 'target': {'description': 'Unique target of the edge', 'title': 'Target', 'type': 'integer'}, 'label': {'description': 'Label of the edge', 'title': 'Label', 'type': 'string'}, 'property': {'description': 'Property of the edge', 'title': 'Property', 'type': 'string'}}, 'required': ['source', 'target', 'label', 'property'], 'title': 'Edge', 'type': 'object'}, 'Node': {'description': 'Node of the Knowledge Graph', 'properties': {'id': {'description': 'Unique identifier of the node', 'title': 'Id', 'type': 'integer'}, 'label': {'description': 'Label of the node', 'title': 'Label', 'type': 'string'}, 'property': {'description': 'Property of the node', 'title': 'Property', 'type': 'string'}}, 'required': ['id', 'label', 'property'], 'title': 'Node', 'type': 'object'}}, 'description': 'Generated Knowledge Graph', 'properties': {'nodes': {'description': 'List of nodes of the knowledge graph', 'items': {'$ref': '#/$defs/Node'}, 'title': 'Nodes', 'type': 'array'}, 'edges': {'description': 'List of edges of the knowledge graph', 'items': {'$ref': '#/$defs/Edge'}, 'title': 'Edges', 'type': 'array'}}, 'required': ['nodes', 'edges'], 'title': 'KnowledgeGraph', 'type': 'object'}\n",
      "</schema><|im_end|>\n",
      "<|im_start|>user\n",
      "Alice loves Bob and she hates Charlie.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<schema>\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Alice loves Bob and she hates Charlie.\"\n",
    "prompt = generate_hermes_prompt(user_prompt)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0608a24-7f39-4ed8-9b6b-d551d9d556a6",
   "metadata": {},
   "source": [
    "We use `generate.regex` by passing the `regex_str` from the Pydantic class we previously defined, and call the generator with the Hermes prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e39197-cf88-4008-8e6d-814dec90a9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:05:04.220341Z",
     "iopub.status.busy": "2024-08-08T18:05:04.219491Z",
     "iopub.status.idle": "2024-08-08T18:05:07.144417Z",
     "shell.execute_reply": "2024-08-08T18:05:07.143798Z",
     "shell.execute_reply.started": "2024-08-08T18:05:04.220292Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = generate.regex(model, regex_str)\n",
    "response = generator(prompt, max_tokens=1024, temperature=0, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0959a-b239-4580-9dec-fad1e3f40211",
   "metadata": {},
   "source": [
    "We obtain the nodes and edges of the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29b7a96d-49fe-4f0c-ba01-a89a2d884194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:05:07.145416Z",
     "iopub.status.busy": "2024-08-08T18:05:07.145203Z",
     "iopub.status.idle": "2024-08-08T18:05:07.149480Z",
     "shell.execute_reply": "2024-08-08T18:05:07.149039Z",
     "shell.execute_reply.started": "2024-08-08T18:05:07.145395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'label': 'Alice', 'property': 'person'},\n",
       " {'id': 2, 'label': 'Bob', 'property': 'person'},\n",
       " {'id': 3, 'label': 'Charlie', 'property': 'person'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_response = json.loads(response)\n",
    "json_response[\"nodes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cca56af-58d5-4efe-9988-f1e141d8e556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:05:07.150178Z",
     "iopub.status.busy": "2024-08-08T18:05:07.150023Z",
     "iopub.status.idle": "2024-08-08T18:05:07.175270Z",
     "shell.execute_reply": "2024-08-08T18:05:07.174648Z",
     "shell.execute_reply.started": "2024-08-08T18:05:07.150163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 1, 'target': 2, 'label': 'love', 'property': 'relationship'},\n",
       " {'source': 1, 'target': 3, 'label': 'hate', 'property': 'relationship'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response[\"edges\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d08fd4-b0f3-45cc-b5c2-19c71baf2b0f",
   "metadata": {},
   "source": [
    "## (Optional) Visualizing the Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce945f-2035-401e-8c8b-98b6d0de2a7e",
   "metadata": {},
   "source": [
    "We can use the [Graphviz library](https://graphviz.readthedocs.io/en/stable/) to visualize the generated knowledge graph. For detailed installation instructions, see [here](https://graphviz.readthedocs.io/en/stable/#installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "580e7367-a5ea-4649-b74d-2ab36ce17459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T18:05:07.176411Z",
     "iopub.status.busy": "2024-08-08T18:05:07.176096Z",
     "iopub.status.idle": "2024-08-08T18:05:07.270015Z",
     "shell.execute_reply": "2024-08-08T18:05:07.268900Z",
     "shell.execute_reply.started": "2024-08-08T18:05:07.176386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"170pt\" height=\"203pt\"\n",
       " viewBox=\"0.00 0.00 170.00 203.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 199)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-199 166,-199 166,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"81\" cy=\"-159\" rx=\"36\" ry=\"36\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-155.3\" font-family=\"Times,serif\" font-size=\"14.00\">Alice</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"36\" cy=\"-36\" rx=\"36\" ry=\"36\"/>\n",
       "<text text-anchor=\"middle\" x=\"36\" y=\"-32.3\" font-family=\"Times,serif\" font-size=\"14.00\">Bob</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.7,-124.94C63.49,-110.93 57.36,-94.44 51.82,-79.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"55.05,-78.18 48.28,-70.02 48.49,-80.62 55.05,-78.18\"/>\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-93.8\" font-family=\"Times,serif\" font-size=\"14.00\">love</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"126\" cy=\"-36\" rx=\"36\" ry=\"36\"/>\n",
       "<text text-anchor=\"middle\" x=\"126\" y=\"-32.3\" font-family=\"Times,serif\" font-size=\"14.00\">Charlie</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.3,-124.94C98.51,-110.93 104.64,-94.44 110.18,-79.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113.51,-80.62 113.72,-70.02 106.95,-78.18 113.51,-80.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-93.8\" font-family=\"Times,serif\" font-size=\"14.00\">hate</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7858dcf2ed10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph()\n",
    "for node in json_response[\"nodes\"]:\n",
    "    dot.node(str(node[\"id\"]), node[\"label\"], shape='circle', width='1', height='1')\n",
    "for edge in json_response[\"edges\"]:\n",
    "    dot.edge(str(edge[\"source\"]), str(edge[\"target\"]), label=edge[\"label\"])\n",
    "\n",
    "dot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
